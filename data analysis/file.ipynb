	
cells	
0	
cell_type	"code"
execution_count	null
id	"e5640e58"
metadata	
scrolled	false
outputs	[]
source	
0	"import pandas as pd\n"
1	"import numpy as np\n"
2	"import matplotlib.pyplot as mpl\n"
3	"import seaborn as sb\n"
4	"import os"
1	
cell_type	"code"
execution_count	null
id	"6b838fef"
metadata	
scrolled	false
outputs	[]
source	
0	"df = pd.read_csv(\"video_games.csv\")\n"
1	"\n"
2	"# first glance at the dataset\n"
3	"df.head()"
2	
cell_type	"code"
execution_count	null
id	"a97d6688"
metadata	{}
outputs	[]
source	
0	"# all the dataset columns \n"
1	"df.columns"
3	
cell_type	"code"
execution_count	null
id	"2253f74b"
metadata	{}
outputs	[]
source	
0	"# ID, name , user_rating and summary are data that may not be soo useful to our studies, therefore we decided\n"
1	"# to remove them, as follows:\n"
2	"df = df.drop('id', axis = 'columns')\n"
3	"df = df.drop('name', axis = 'columns')\n"
4	"df = df.drop('user_score', axis = 'columns')\n"
5	"df = df.drop('summary', axis = 'columns')\n"
6	"df = df.drop('companies', axis = 'columns')"
4	
cell_type	"code"
execution_count	null
id	"5ab53e59"
metadata	{}
outputs	[]
source	
0	"# we also removed null values, since there's not a significant amount of them \n"
1	"df = df.dropna()\n"
2	"df.info()"
5	
cell_type	"code"
execution_count	null
id	"a4bdcd46"
metadata	
scrolled	false
outputs	[]
source	
0	"#separation of genres and respective one-hot encoding\n"
1	"allGenres = []\n"
2	"allLines = []\n"
3	"for line in df['genres']:\n"
4	"    lineGenres = line.split(\", \")\n"
5	"    allLines.append(lineGenres)\n"
6	"    for genre in lineGenres:\n"
7	"        if genre not in allGenres:\n"
8	"            allGenres.append(genre)\n"
9	"\n"
10	"for genree in allGenres:\n"
11	"    current = []\n"
12	"    i = 0\n"
13	"    for linne in allLines:\n"
14	"        for a in linne:\n"
15	"            if a == genree:\n"
16	"                current.append(1)\n"
17	"                i = 1\n"
18	"                continue\n"
19	"        if i == 0:\n"
20	"            current.append(0)\n"
21	"        i = 0\n"
22	"    name_of_current = 'g_' + genree\n"
23	"    df[name_of_current] = current\n"
24	"    \n"
25	"df = df.drop('genres', axis = 'columns')    \n"
26	"df.head()"
6	
cell_type	"code"
execution_count	null
id	"77aef22c"
metadata	
scrolled	true
outputs	[]
source	
0	"# separation of platforms and respective one-hot encoding\n"
1	"allPlaforms = []\n"
2	"allLines = []\n"
3	"for line in df['platforms']:\n"
4	"    linePlaforms = line.split(\", \")\n"
5	"    allLines.append(linePlaforms)\n"
6	"    for plat in linePlaforms:\n"
7	"        if plat not in allPlaforms:\n"
8	"            allPlaforms.append(plat)\n"
9	"\n"
10	"for platt in allPlaforms:\n"
11	"    current = []\n"
12	"    i = 0\n"
13	"    for linne in allLines:\n"
14	"        for a in linne:\n"
15	"            if a == platt:\n"
16	"                current.append(1)\n"
17	"                i = 1\n"
18	"                continue\n"
19	"        if i == 0:\n"
20	"            current.append(0)\n"
21	"        i = 0\n"
22	"    name_of_current = 'p_' + platt\n"
23	"    df[name_of_current] = current\n"
24	"    \n"
25	"df = df.drop('platforms', axis = 'columns')    \n"
7	
cell_type	"code"
execution_count	null
id	"b5245afd"
metadata	{}
outputs	[]
source	
0	"# transforming string columns into numerical information \n"
1	"from sklearn import preprocessing\n"
2	"cat = preprocessing.LabelEncoder()\n"
3	"\n"
4	"df['category'] = cat.fit_transform(df['category'])\n"
5	"\n"
6	"# histogram for all the categories\n"
7	"df['category'].hist()"
8	
cell_type	"code"
execution_count	null
id	"d183454e"
metadata	{}
outputs	[]
source	
0	"from sklearn import preprocessing\n"
1	"rat = preprocessing.LabelEncoder()\n"
2	"\n"
3	"df['user_rating'] = rat.fit_transform(df['user_rating'])\n"
4	"\n"
5	"# histogram for the user rating\n"
6	"df['user_rating'].hist()"
9	
cell_type	"code"
execution_count	null
id	"39039e11"
metadata	{}
outputs	[]
source	
0	"list(rat.transform(['great', 'good', 'mediocre', 'bad'])) # 0 = bad, 1 = good, 2 = great, 3 = mediocre "
10	
cell_type	"code"
execution_count	null
id	"6280f15e"
metadata	{}
outputs	[]
source	
0	"# transforming True or False stings into 1 or 0 integers \n"
1	"df['in_franchise'] = df['in_franchise'].astype(int)\n"
2	"df['in_franchise'].head() "
11	
cell_type	"code"
execution_count	null
id	"6f515c1a"
metadata	{}
outputs	[]
source	
0	"# we created a heatmap with all the columns from the clean data\n"
1	"heatMap = df.corr()\n"
2	"sb.heatmap(heatMap)"
12	
cell_type	"code"
execution_count	null
id	"4e24c2de"
metadata	{}
outputs	[]
source	
0	"# checking what's the most significant column in the dataset compared to user_rating \n"
1	"HM = heatMap['user_rating'].drop(['user_rating'])\n"
2	"max = HM.max()\n"
3	"HM[HM == max]"
13	
cell_type	"code"
execution_count	null
id	"851072c8"
metadata	{}
outputs	[]
source	
0	"# heatmap relating all the geners and user_rating\n"
1	"genres = [col for col in df if col.startswith('g_')]\n"
2	"gen = df[['user_rating'] + genres]\n"
3	"\n"
4	"G = gen.corr()\n"
5	"sb.heatmap(G,cmap = \"BuPu\")"
14	
cell_type	"code"
execution_count	null
id	"715a2dc8"
metadata	{}
outputs	[]
source	
0	"# what is the most influencial gener?\n"
1	"GEN = G['user_rating'].drop(['user_rating'])\n"
2	"max = GEN.max()\n"
3	"GEN[GEN == max]"
15	
cell_type	"code"
execution_count	null
id	"5205a2ab"
metadata	{}
outputs	[]
source	
0	"# heatmap relating all the platforms and user_rating\n"
1	"platforms = [col for col in df if col.startswith('p_')]\n"
2	"plat = df[['user_rating'] + platforms]\n"
3	"\n"
4	"P = plat.corr()\n"
5	"sb.heatmap(P,cmap = \"BuPu\")"
16	
cell_type	"code"
execution_count	null
id	"530c77fe"
metadata	{}
outputs	[]
source	
0	"# what is the most influencial platform?\n"
1	"PLAT = P['user_rating'].drop(['user_rating'])\n"
2	"max = PLAT.max()\n"
3	"PLAT[PLAT == max]"
17	
cell_type	"code"
execution_count	null
id	"55d79c3c"
metadata	{}
outputs	[]
source	
0	"# dividing the data into a train and test dataframes so we can compare accuracies \n"
1	"from sklearn.model_selection import train_test_split\n"
2	"\n"
3	"dff = df.drop('user_rating', axis = 'columns')\n"
4	"x = dff\n"
5	"y = df[['user_rating']]\n"
6	"\n"
7	"seed = 1111\n"
8	"xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.3, random_state = seed, stratify = y)"
18	
cell_type	"code"
execution_count	null
id	"c45b62da"
metadata	{}
outputs	[]
source	
0	"# Dummy Classifier (Control)\n"
1	"from sklearn.dummy import DummyClassifier\n"
2	"\n"
3	"dummy_clf = DummyClassifier(strategy = 'most_frequent')\n"
4	"dummy_clf.fit(xTrain, yTrain)\n"
5	"\n"
6	"predict_test = dummy_clf.predict(xTest) \n"
7	"predict_train = dummy_clf.predict(xTrain) \n"
8	"\n"
9	"print(\"Train Accuracy (D):\")\n"
10	"acc_train = sum(predict_train == yTrain['user_rating'])/len(yTrain)\n"
11	"print(acc_train)\n"
12	"\n"
13	"\n"
14	"print(\"Test Accuracy (D):\")\n"
15	"acc_test = sum(predict_test == yTest['user_rating'])/len(yTest)\n"
16	"print(acc_test)"
19	
cell_type	"code"
execution_count	null
id	"5eb3cfa8"
metadata	{}
outputs	[]
source	
0	"# Dummy's model confusion matrix \n"
1	"from sklearn.metrics import confusion_matrix\n"
2	"y_true = yTest\n"
3	"y_pred = predict_test\n"
4	"cm_d = confusion_matrix(y_true, y_pred)\n"
5	"\n"
6	"classifiers = ['T Bad','F Good','F Great','F Mediocre','F Bad','T Good','F Great','F Mediocre',\n"
7	"               'F Bad','F Good','T Great','F Mediocre','F Bad','F Good','F Great','T Mediocre']\n"
8	"percentages = [\"{0:.2%}\".format(value) for value in cm_d.flatten()/np.sum(cm_d)]\n"
9	"\n"
10	"labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(classifiers,percentages)]\n"
11	"labels = np.asarray(labels).reshape(4,4)\n"
12	"\n"
13	"ax = sb.heatmap(cm_d/np.sum(cm_d), annot = labels, fmt = '', cmap = \"BuPu\")\n"
14	"\n"
15	"ax.set_title('Dummy Confusion Matrix\\n')\n"
16	"ax.set_xlabel('\\nPredicted Values')\n"
17	"ax.set_ylabel('Actual Values\\n')\n"
18	"ax.xaxis.set_ticklabels(['Bad','Good','Great','Mediocre'])\n"
19	"ax.yaxis.set_ticklabels(['Bad','Good','Great','Mediocre'])"
20	
cell_type	"code"
execution_count	null
id	"d75695f7"
metadata	{}
outputs	[]
source	
0	"# Learning Curve of the model, how accuracy changes with the increment of the amount of data\n"
1	"from sklearn.model_selection import learning_curve\n"
2	"\n"
3	"train_sizes, train_scores, test_scores = learning_curve(estimator = dummy_clf, X = xTrain, random_state = seed, \n"
4	"                   y = yTrain, train_sizes = [10, 25, 50, 100, 300,500,1000,1500,2000,3000,3200])\n"
5	"\n"
6	"train_mean = train_scores.mean(axis = 1)\n"
7	"test_mean = test_scores.mean(axis = 1)\n"
8	"\n"
9	"mpl.plot(train_sizes, train_mean, label = 'train')\n"
10	"mpl.plot(train_sizes, test_mean, label = 'test')\n"
11	"\n"
12	"mpl.legend()\n"
13	"mpl.ylabel(\"Accuracy\")\n"
14	"mpl.xlabel(\"n_Cases_Analyzed\")\n"
15	"mpl.title(\"Dummy Learning Curve \\n\")"
21	
cell_type	"code"
execution_count	null
id	"56f68fa9"
metadata	{}
outputs	[]
source	
0	"# we tested the Dummy algorithtm with different strategies\n"
1	"# in the best case scenario we achieved 0.5485353245261344 acc\n"
2	"\n"
3	"strategies = ['most_frequent', 'prior', 'stratified', 'uniform']\n"
4	"accuracies = [0.5485353245261344, 0.5485353245261344, 0.48822515795519816, 0.24009190120620333]"
22	
cell_type	"code"
execution_count	null
id	"915bdea3"
metadata	{}
outputs	[]
source	
0	"# Decision Tree\n"
1	"from sklearn.tree import DecisionTreeClassifier\n"
2	"\n"
3	"df1 = DecisionTreeClassifier(criterion = \"gini\", max_leaf_nodes = 25, random_state = seed)\n"
4	"df1.fit(xTrain, yTrain)\n"
5	"\n"
6	"xPred = df1.predict(xTrain)     \n"
7	"trainAccuracy = sum(xPred == yTrain['user_rating'])/len(yTrain)\n"
8	"\n"
9	"print(\"Train Accuracy (DT):\")\n"
10	"print(trainAccuracy)    \n"
11	"\n"
12	"xPred1 = df1.predict(xTest)      \n"
13	"testAccuracy = sum(xPred1 == yTest['user_rating'])/len(yTest)\n"
14	"\n"
15	"print(\"Test Accuracy (DT):\")\n"
16	"print(testAccuracy)  "
23	
cell_type	"code"
execution_count	null
id	"fd354849"
metadata	{}
outputs	[]
source	
0	"# Learning Curve of the model, how accuracy changes with the increment of the amount of data\n"
1	"from sklearn.model_selection import learning_curve\n"
2	"\n"
3	"train_sizes, train_scores, test_scores = learning_curve(estimator = df1, X = xTrain, random_state = seed, \n"
4	"                   y = yTrain, train_sizes = [10, 25, 50, 100, 300,500,1000,1500,2000,3000,3200])\n"
5	"\n"
6	"train_mean = train_scores.mean(axis = 1)\n"
7	"test_mean = test_scores.mean(axis = 1)\n"
8	"\n"
9	"mpl.plot(train_sizes, train_mean, label = 'train')\n"
10	"mpl.plot(train_sizes, test_mean, label = 'test')\n"
11	"\n"
12	"mpl.legend()\n"
13	"mpl.ylabel(\"Accuracy\")\n"
14	"mpl.xlabel(\"n_Cases_Analyzed\")\n"
15	"mpl.title(\"Decision Tree Learning Curve \\n\")"
24	
cell_type	"code"
execution_count	null
id	"d6c13f32"
metadata	{}
outputs	[]
source	
0	"# we created a loop to check which is the best max_leaf_nodes to work with\n"
1	"maxAcc = 0\n"
2	"Acc = 0\n"
3	"i = 2\n"
4	"maxi = 2\n"
5	"\n"
6	"while i <= 100:\n"
7	"    nodes = DecisionTreeClassifier(criterion = \"gini\", max_leaf_nodes = i, random_state = seed)\n"
8	"    nodes.fit(xTrain, yTrain)   \n"
9	"    \n"
10	"    x_nodes_Pred = nodes.predict(xTest)      \n"
11	"    testAccuracy = sum(x_nodes_Pred == yTest['user_rating'])/len(yTest)\n"
12	"    \n"
13	"    Acc = testAccuracy \n"
14	"    if Acc > maxAcc:\n"
15	"        maxAcc = Acc\n"
16	"        maxi = i\n"
17	"    i += 1\n"
18	"    \n"
19	"print(maxAcc, maxi)\n"
20	"# therefore we'll be using 25 max_leaf_node"
25	
cell_type	"code"
execution_count	null
id	"0654236e"
metadata	{}
outputs	[]
source	
0	"# DT's model confusion matrix \n"
1	"y_true = yTest\n"
2	"y_pred = xPred1\n"
3	"cm_dt = confusion_matrix(y_true, y_pred)\n"
4	"\n"
5	"classifiers = ['T Bad','F Good','F Great','F Mediocre','F Bad','T Good','F Great','F Mediocre',\n"
6	"               'F Bad','F Good','T Great','F Mediocre','F Bad','F Good','F Great','T Mediocre']\n"
7	"percentages = [\"{0:.2%}\".format(value) for value in cm_dt.flatten()/np.sum(cm_dt)]\n"
8	"\n"
9	"labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(classifiers,percentages)]\n"
10	"labels = np.asarray(labels).reshape(4,4)\n"
11	"\n"
12	"ay = sb.heatmap(cm_dt/np.sum(cm_dt), annot = labels, fmt = '', cmap = \"BuPu\")\n"
13	"\n"
14	"ay.set_title('Decision Tree Confusion Matrix\\n')\n"
15	"ay.set_xlabel('\\nPredicted Values')\n"
16	"ay.set_ylabel('Actual Values\\n')\n"
17	"ay.xaxis.set_ticklabels(['Bad','Good','Great','Mediocre'])\n"
18	"ay.yaxis.set_ticklabels(['Bad','Good','Great','Mediocre'])"
26	
cell_type	"code"
execution_count	null
id	"88f1af77"
metadata	{}
outputs	[]
source	
0	"# plotting the Decision Tree\n"
1	"from sklearn import tree\n"
2	"import matplotlib.pyplot as plt\n"
3	"\n"
4	"plt.figure(figsize = (40, 20))\n"
5	"columns_names = dff.columns\n"
6	"\n"
7	"a = tree.plot_tree(df1, rounded = True, filled = True, fontsize = 12,feature_names = columns_names, \n"
8	"                   class_names = ['bad', 'good', 'great', 'mediocre'])\n"
9	"plt.show()"
27	
cell_type	"code"
execution_count	null
id	"c08010df"
metadata	{}
outputs	[]
source	
0	"# KNN Algorithm \n"
1	"from sklearn.neighbors import KNeighborsClassifier\n"
2	"knn = KNeighborsClassifier(n_neighbors = 5)\n"
3	"knn.fit(xTrain, yTrain.values.ravel())\n"
4	" \n"
5	"# Calculate the accuracy of the model\n"
6	"print(\"Train Accuracy (KNN):\")\n"
7	"print(knn.score(xTrain, yTrain))\n"
8	"\n"
9	"print(\"Test Accuracy (KNN):\")\n"
10	"print(knn.score(xTest, yTest))"
28	
cell_type	"code"
execution_count	null
id	"529e6da7"
metadata	{}
outputs	[]
source	
0	"# KNN's model confusion matrix \n"
1	"y_true = yTest\n"
2	"y_pred = knn.predict(xTest)\n"
3	"cm_knn = confusion_matrix(y_true, y_pred)\n"
4	"\n"
5	"classifiers = ['T Bad','F Good','F Great','F Mediocre','F Bad','T Good','F Great','F Mediocre',\n"
6	"               'F Bad','F Good','T Great','F Mediocre','F Bad','F Good','F Great','T Mediocre']\n"
7	"percentages = [\"{0:.2%}\".format(value) for value in cm_knn.flatten()/np.sum(cm_knn)]\n"
8	"\n"
9	"labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(classifiers,percentages)]\n"
10	"labels = np.asarray(labels).reshape(4,4)\n"
11	"\n"
12	"az = sb.heatmap(cm_knn/np.sum(cm_knn), annot = labels, fmt = '', cmap = \"BuPu\")\n"
13	"\n"
14	"az.set_title('K-Nearest Neighbour Confusion Matrix\\n')\n"
15	"az.set_xlabel('\\nPredicted Values')\n"
16	"az.set_ylabel('Actual Values\\n')\n"
17	"az.xaxis.set_ticklabels(['Bad','Good','Great','Mediocre'])\n"
18	"az.yaxis.set_ticklabels(['Bad','Good','Great','Mediocre'])"
29	
cell_type	"code"
execution_count	null
id	"88229bff"
metadata	{}
outputs	[]
source	
0	"# Learning Curve of the model, how accuracy changes with the increment of the amount of data\n"
1	"from sklearn.model_selection import learning_curve\n"
2	"\n"
3	"train_sizes, train_scores, test_scores = learning_curve(estimator = knn, X = xTrain, random_state = seed, \n"
4	"                   y = yTrain, train_sizes = [10, 25, 50, 100, 300,500,1000,1500,2000,3000,3200])\n"
5	"\n"
6	"train_mean = train_scores.mean(axis = 1)\n"
7	"test_mean = test_scores.mean(axis = 1)\n"
8	"\n"
9	"mpl.plot(train_sizes, train_mean, label = 'train')\n"
10	"mpl.plot(train_sizes, test_mean, label = 'test')\n"
11	"\n"
12	"plt.legend()\n"
13	"mpl.ylabel(\"Accuracy\")\n"
14	"mpl.xlabel(\"n_Cases_Analyzed\")\n"
15	"mpl.title(\"K-Nearest Neighbour Learning Curve \\n\")\n"
16	"\n"
17	"# unfortunately we ran into an error while loading this plot, although we still got a usable outcome "
30	
cell_type	"code"
execution_count	null
id	"24e9732b"
metadata	{}
outputs	[]
source	
0	"# accuracy variation based on K values\n"
1	"neighbors = np.arange(1, 25)\n"
2	"train_accuracy = np.empty(len(neighbors))\n"
3	"test_accuracy = np.empty(len(neighbors))\n"
4	" \n"
5	"# loop over K values\n"
6	"for i, k in enumerate(neighbors):\n"
7	" \n"
8	"    knn = KNeighborsClassifier(n_neighbors = k)\n"
9	"    knn.fit(xTrain, yTrain.values.ravel())\n"
10	"     \n"
11	"    # Compute training and test data accuracy\n"
12	"    train_accuracy[i] = knn.score(xTrain, yTrain)\n"
13	"    test_accuracy[i] = knn.score(xTest, yTest)\n"
14	" \n"
15	"\n"
16	"# create the plot\n"
17	"plt.plot(neighbors, test_accuracy, label = 'test accuracy (KNN)')\n"
18	"plt.plot(neighbors, train_accuracy, label = 'train accuracy (KNN)')\n"
19	" \n"
20	"plt.legend()\n"
21	"plt.xlabel('n_neighbors')\n"
22	"plt.ylabel('Accuracy')\n"
23	"plt.show()"
31	
cell_type	"code"
execution_count	null
id	"4a9427fb"
metadata	{}
outputs	[]
source	
0	"# testing all the models above for different seeds\n"
1	"from sklearn.model_selection import train_test_split\n"
2	"seeds = [245, 4721, 2549, 8201, 13, 17, 9714, 841, 1111, 123, 3324, 2272, 1410, 69, 0, 33, 8888]\n"
3	"\n"
4	"Test_D = []\n"
5	"Train_D = []\n"
6	"Test_DT = []\n"
7	"Train_DT = []\n"
8	"Test_KNN = []\n"
9	"Train_KNN = []\n"
10	"\n"
11	"for seed in range(len(seeds)):\n"
12	"    dff = df.drop('user_rating', axis = 'columns')\n"
13	"    x = dff\n"
14	"    y = df[['user_rating']]\n"
15	"\n"
16	"    seed = seeds[seed]\n"
17	"    xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.3, random_state = seed, stratify = y)\n"
18	"\n"
19	"    \n"
20	"    # Dummy Classifier (Control)\n"
21	"    from sklearn.dummy import DummyClassifier\n"
22	"\n"
23	"    dummy = DummyClassifier(strategy = 'most_frequent')\n"
24	"    dummy.fit(xTrain, yTrain)\n"
25	"\n"
26	"    pred_test = dummy.predict(xTest) \n"
27	"    pred_train = dummy.predict(xTrain) \n"
28	"\n"
29	"    acc_train = sum(pred_train == yTrain['user_rating'])/len(yTrain)\n"
30	"    Train_D.append(acc_train)\n"
31	"    \n"
32	"    acc_test = sum(pred_test == yTest['user_rating'])/len(yTest)\n"
33	"    Test_D.append(acc_test)\n"
34	"    \n"
35	"    \n"
36	"    # Decision Tree\n"
37	"    from sklearn.tree import DecisionTreeClassifier\n"
38	"\n"
39	"    tree = DecisionTreeClassifier(criterion = \"gini\", max_leaf_nodes = 25, random_state = seed)\n"
40	"    tree.fit(xTrain, yTrain)\n"
41	"\n"
42	"    xPred = tree.predict(xTrain)     \n"
43	"    trainAccuracy = sum(xPred == yTrain['user_rating'])/len(yTrain)\n"
44	"    Train_DT.append(trainAccuracy) \n"
45	"\n"
46	"    xPred1 = tree.predict(xTest)      \n"
47	"    testAccuracy = sum(xPred1 == yTest['user_rating'])/len(yTest)\n"
48	"    Test_DT.append(testAccuracy) \n"
49	"\n"
50	"    \n"
51	"    # KNN Algorithm \n"
52	"    from sklearn.neighbors import KNeighborsClassifier\n"
53	"\n"
54	"    knn1 = KNeighborsClassifier(n_neighbors = 5)\n"
55	"    knn1.fit(xTrain, yTrain.values.ravel())\n"
56	"    \n"
57	"    train = knn1.score(xTrain, yTrain)\n"
58	"    Train_KNN.append(train)\n"
59	"\n"
60	"    test = knn1.score(xTest, yTest)\n"
61	"    Test_KNN.append(test)\n"
62	"\n"
63	"\n"
64	"Acc = pd.DataFrame({'seed' : seeds, 'Train_Acc_D' :  Train_D, 'Test_Acc_D' : Test_D,\n"
65	"                    'Train_Acc_DT' :  Train_DT, 'Test_Acc_DT' : Test_DT,\n"
66	"                    'Train_Acc_KNN' :  Train_KNN, 'Test_Acc_KNN' : Test_KNN})\n"
67	"\n"
68	"Acc"
metadata	
interpreter	
hash	"eb5bb8b75490dc04ffc9425efe8e22fc82364cda56f44ebe9caf714aef31daaa"
kernelspec	
display_name	"Python 3 (ipykernel)"
language	"python"
name	"python3"
language_info	
codemirror_mode	
name	"ipython"
version	3
file_extension	".py"
mimetype	"text/x-python"
name	"python"
nbconvert_exporter	"python"
pygments_lexer	"ipython3"
version	"3.9.7"
nbformat	4
nbformat_minor	5
