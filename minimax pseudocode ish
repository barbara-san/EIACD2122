
amount of pieces eaten
if opponent can move there, amount of pieces lost




def minimax(node, depth, maxplayer):
	// if depth == 0 or node == terminal_node:
		// return static evaluation of node  
	if maxplayer:                                          // for max  
		maxvalue = -infinity                                                 // library or use giant number
		for each child of node: 
			value = minimax(child, depth-1, false)  
			if value > maxvalue:
				maxvalue = value                                                   // gives maximum of the values  (or use max() function)
		return maxvalue  
	else:                                                  // for min
		minvalue= +infinity                                                   // library or use giant number
		for each child of node: 
			value = minimax(child, depth-1, true)  
			if value < minvalue:
				minvalue = value                                                    // gives minimum of the values  (or use min() function)
		return minvalue 

def findBestMove(moves):
    bestMove = null
    for i in moves:
        if current move is better than bestMove
            bestMove = current move
    return bestMove
aaa



def minimax2(node, depth, alpha, beta, maxplayer):                 //beta-alpha pruning
    // if depth == 0 or node == terminal_node:
        // return static evaluation of node
    if maxplayer:
        value = -infinity    
        for each child of node:
            value = max(value, minimax2(child, depth − 1, alpha, beta, false))
            if value >= beta then
                break
            alpha = max(alpha, value)
        return value
    else
        value = +infinity    
        for each child of node:
            value = min(value, minimax2(child, depth − 1, alpha, beta, true))
            if value <= alpha:
                break
            beta = min(beta, value)
        return value









def minimax (curDepth, nodeIndex, maxplayer, scores, targetDepth):
	# base case : targetDepth reached
	if (curDepth == targetDepth):
		return scores[nodeIndex]
	if maxplayer:
		return max(minimax(curDepth + 1, nodeIndex * 2, False, scores, targetDepth), minimax(curDepth + 1, nodeIndex * 2 + 1, False, scores, targetDepth))
	
	else:
		return min(minimax(curDepth + 1, nodeIndex * 2, True, scores, targetDepth), minimax(curDepth + 1, nodeIndex * 2 + 1, True, scores, targetDepth))
	
# Driver code
scores = [3, 5, 2, 9, 12, 5, 23, 23]

treeDepth = math.log(len(scores), 2)

print("The optimal value is : ", end = "")
print(minimax(0, 0, True, scores, treeDepth))

# This code is contributed
# by rootshadow






















def minimax3(node, depth, maxplayer, alpha, beta)            // alpha beta pruning with less skips
	if maxplayer:
        bestvalue = -infinity
        for each child node:
            value = minimax3(node, depth+1, false, alpha, beta)
            bestvalue = max(bestvalue, value) 
            alpha = max(alpha, bestvalue)
            if beta <= alpha:
                break
        return bestvalue

    else :
        bestvalue = +infinity 
        for each child node:
            value = minimax3(node, depth+1, true, alpha, beta)
            bestvalue = min(bestvalue, value) 
            beta = min(beta, bestvalue)
            if beta <= alpha:
                break
		return bestvalue





































logica
movimento interface
lista movimentos possiveis
blabla 

codigo greedy
minimax, pc vs pc (different depths)

treesearch, heuristics

exame_
in 2 weeks moodle, computador
1 pergunta pratica sobre pesquisa, pesquisa sobre adversarios
perguntas parecidas kahoot, por correspondencia possibly, materia das teoricas
consulta


class breath:
    def __init__(self,node, maxplayer):
        self.children = []
        self.parent = None
        self.parentAction = None
    
    def __str__(self):
        return current tabuleiro

    def add_child(self,child):
        self.children.append(child)
        child.parent = self

    def show_path(self):
        resposta = [self] #este node é o estado objetivo
        while self.parent != None:
            resposta.insert(0, self.parent) #adicionar o estado "parent" à esquerda na lista
            self = self.parent
        output = str(resposta[0])
        for state in resposta[1:]:
            output += " -%s-> %s" % (state.parentAction, str(state))
        return output

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Heuristics
A heuristic is a formula that connects a score to each board. Usually, the score is higher when the odds are better for the current player. A winning board should have the highest score and a losing board the lowest score.

Heuristics are important for the computer player to decide which move it has to make. If there are two possible moves, the one resulting in a board state with the highest score will be chosen. This score is the heuristic value, determined by the heuristic.

Heuristics are fallible. There is no heuristic that gives the best moves the best scores. A heuristic is just a informed guess about how things are doing for the computer player. The more "smart", or informed, the heuristic is, the more time it will take to calculate the heuristic value for a board.

Heuristics are usually described as:
h(n) = heuristic value for state n
State n is in our case a particular board state, e.g. where the black and white pieces are located.

These are just some examples of heuristics, there are many more possible.

Number of black pieces
One of the most simple heuristics is
h(n) = count(black_pieces)
or white pieces, for that matter.

This heuristic is fairly easy to compute. However, in the game of ataxx, the number of stones can change very quickly (max. 8 stones in one move). This means that this heuristic is somewhat crude and does not give a very informed guess. As we shall see, this can be solved a bit by searching a bigger part of the state space.

This heuristic can be a bit modified by giving losing boards a very low number and winning boards a very high heuristic value. A losing board is a state destined to be lost by the computer player, usually just before the game is over. This avoids committing suicide by choosing a losing combination.

Number of black pieces minus number of white pieces
This heuristic also considers how the opponent is doing:
h(n) = count(black_pieces) - count(white_pieces)
This seems like a better heuristic, for marginal higher costs, but most algorithms which use heuristics also consider the opponents move, so that this addition is not really needed.

Extra score for surrounded pieces
Black pieces surrounded on all sides by other black pieces are hard for the opponent to take over. If there is a border of two pieces around a particular piece, it is even harder.
h(n) = count(black_pieces) + a * pieces_with_border(1, black) + b * pieces_with_border(2, black)
a and b are constants with values that are either experimentally found or figured out by the program itself.
Rakesh came up with a nice idea: to randomly alter the constants a bit so that the playing style is different every time. This avoids predictable moves.

This heuristic may make the computer player smarter, or it may not. With more complex functions it is often hard to see if it works out OK.

Algorithms
An algorithm chooses the best move out of some or all possible moves. It usually works by thinking what would happen if a move is done. It does that by examining the heuristic value of each board which results after a move.

First some graph theory: a node is a board state. The children of this node are all boards that can be reached in one move.

Minimax
Minimax is an algorithm for games with more as one player. It searches the states beneath the current one to a current depth. This depth is called the ply depth, and the computer "looks ahead" for this many moves.

Minimax tries to maximize the advantage for the current player, while minimizing the advantage for the other player. It assumes that the other player does the same.

When it is black's turn, he can choose the best move out of all possible moves. The moves resulting in bad states are therefore not relevant. However, when white is moving, it will probably pick the move that is best for him and hence, very bad for black. Then the good moves (for black, that is) don't matter as much.

In minimax, all heuristic values of the nodes on a certain ply depth are evaluated. These values are then traversed to the top in a particular way: if in this ply it is black's turn, the heuristic values of a node is the maximum of the node's below. If white is moving in this ply, the heuristic values of the nodes are the minimum of the node's below.

For all leaves (nodes on the maximum search depth):
h(n) = h1(n)
where h1(n) is a certain heuristic function for state n.
For all nodes where it is black's turn:
h(n) = MAX(child1, child2, ..., childn)
For all nodes where it is white's turn:
h(n) = MIN(child1, child2, ..., childn)

With the functions above, all board states have a heuristic value and the best move can be chosen.

A disadvantage of the minimax algorithm is that each board state has to be visited twice: one time to find its children and a second time to evaluate the heuristic value.

Alpha-beta pruning
Alpha-beta pruning is a optimized form of minimax. It is almost the same, except that it searches the state space in a depth-first search. This enables it to cleverly skip parts of the search tree.

For example, it could be that the computer has to calculate the following in order to evaluate a heuristic value for a node:
MIN(3, MAX(5, a))
Here the variable a is unknown, but that is not really a problem. MAX(5, a) is at least 5, and MIN(3, b) where b is 5 or more is just 3. Alpha-beta pruning thus skips the tree under a.
