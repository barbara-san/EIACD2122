
amount of pieces eaten




def minimax(node, depth, maxplayer):
	// if depth == 0 or node == terminal_node:
		// return static evaluation of node  
	if maxplayer:                                          // for max  
		maxvalue = -infinity                                                 // library or use giant number
		for each child of node: 
			value = minimax(child, depth-1, false)  
			if value > maxvalue:
				maxvalue = value                                                   // gives maximum of the values  (or use max() function)
		return maxvalue  
	else:                                                  // for min
		minvalue= +infinity                                                   // library or use giant number
		for each child of node: 
			value = minimax(child, depth-1, true)  
			if value < minvalue:
				minvalue = value                                                    // gives minimum of the values  (or use min() function)
		return minvalue 

def findBestMove(moves):
    bestMove = null
    for i in moves:
        if current move is better than bestMove
            bestMove = current move
    return bestMove




def minimax2(node, depth, alpha, beta, maxplayer):                 //beta-alpha pruning
    // if depth == 0 or node == terminal_node:
        // return static evaluation of node
    if maxplayer:
        value = -infinity    
        for each child of node:
            value = max(value, minimax2(child, depth − 1, alpha, beta, false))
            if value >= beta then
                break
            alpha = max(alpha, value)
        return value
    else
        value = +infinity    
        for each child of node:
            value = min(value, minimax2(child, depth − 1, alpha, beta, true))
            if value <= alpha:
                break
            beta = min(beta, value)
        return value









def minimax (curDepth, nodeIndex, maxplayer, scores, targetDepth):
	# base case : targetDepth reached
	if (curDepth == targetDepth):
		return scores[nodeIndex]
	if maxplayer:
		return max(minimax(curDepth + 1, nodeIndex * 2, False, scores, targetDepth), minimax(curDepth + 1, nodeIndex * 2 + 1, False, scores, targetDepth))
	
	else:
		return min(minimax(curDepth + 1, nodeIndex * 2, True, scores, targetDepth), minimax(curDepth + 1, nodeIndex * 2 + 1, True, scores, targetDepth))
	
# Driver code
scores = [3, 5, 2, 9, 12, 5, 23, 23]

treeDepth = math.log(len(scores), 2)

print("The optimal value is : ", end = "")
print(minimax(0, 0, True, scores, treeDepth))

# This code is contributed
# by rootshadow






















def minimax3(node, depth, maxplayer, alpha, beta)            // alpha beta pruning with less skips
	if maxplayer:
        bestvalue = -infinity
        for each child node:
            value = minimax3(node, depth+1, false, alpha, beta)
            bestvalue = max(bestvalue, value) 
            alpha = max(alpha, bestvalue)
            if beta <= alpha:
                break
        return bestvalue

    else :
        bestvalue = +infinity 
        for each child node:
            value = minimax3(node, depth+1, true, alpha, beta)
            bestvalue = min(bestvalue, value) 
            beta = min(beta, bestvalue)
            if beta <= alpha:
                break
		return bestvalue











































class breath:
    def __init__(self,node, maxplayer):
        self.children = []
        self.parent = None
        self.parentAction = None
    
    def __str__(self):
        return current tabuleiro

    def add_child(self,child):
        self.children.append(child)
        child.parent = self

    def show_path(self):
        resposta = [self] #este node é o estado objetivo
        while self.parent != None:
            resposta.insert(0, self.parent) #adicionar o estado "parent" à esquerda na lista
            self = self.parent
        output = str(resposta[0])
        for state in resposta[1:]:
            output += " -%s-> %s" % (state.parentAction, str(state))
        return output

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
For all leaves (nodes on the maximum search depth):
h(n) = h1(n)
where h1(n) is a certain heuristic function for state n.
For all nodes where it is black's turn:
h(n) = MAX(child1, child2, ..., childn)
For all nodes where it is white's turn:
h(n) = MIN(child1, child2, ..., childn)
With the functions above, all board states have a heuristic value and the best move can be chosen.

Alpha-beta pruning
Alpha-beta pruning is a optimized form of minimax. It is almost the same, except that it searches the state space in a depth-first search.
This enables it to cleverly skip parts of the search tree.
For example, it could be that the computer has to calculate the following in order to evaluate a heuristic value for a node:
MIN(3, MAX(5, a))
Here the variable a is unknown, but that is not really a problem. MAX(5, a) is at least 5, and MIN(3, b) where b is 5 or more is just 3.
Alpha-beta pruning thus skips the tree under a.
